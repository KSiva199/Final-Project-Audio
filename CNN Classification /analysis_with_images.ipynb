{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI-3fl0pXBfc",
        "outputId": "a2b8734b-4f12-4282-c842-ee3fffc03597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #file saving location\n",
        "images_dir = '/content/gdrive/My Drive/Colab Notebooks/Classes/IA 651/Audio-data-classification/Spectro_imgs/'"
      ],
      "metadata": {
        "id": "LHsZlyi4XVU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "SX7QEP8AYR9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All images are of Width: 100 Height: 128"
      ],
      "metadata": {
        "id": "NvOSItbmxce8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for digit in range(1):\n",
        "    # Directory of wav files\n",
        "    folder_path = f\"{images_dir}{digit}/\"\n",
        "    file_list = glob.glob(os.path.join(folder_path, '*'))\n",
        "\n",
        "    for i, img_path  in enumerate(file_list):\n",
        "    #   # Open the image file\n",
        "      image = Image.open(f\"{img_path}\")\n",
        "\n",
        "    #   # Get the size of the image\n",
        "      width, height = image.size\n",
        "\n",
        "      print(f\"Width: {width} Height: {height}\")\n",
        "\n",
        "              "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svOkJYqeYc2L",
        "outputId": "f6300a16-d318-4e61-ed64-436976e22a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n",
            "Width: 100 Height: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "QcQMJhcUDmPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_width, img_height = 100, 128\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQNm-I86bL66",
        "outputId": "cf833904-5c3a-48be-e260-5069613a2cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 195 images belonging to 10 classes.\n",
            "Found 45 images belonging to 10 classes.\n",
            "Found 240 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "o9nLyj-VyBq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.n//validation_generator.batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUczz_GxDIOp",
        "outputId": "96c68d30-dd25-4d4c-c3e5-e385466ca1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 111s 21s/step - loss: 2.3135 - accuracy: 0.1166 - val_loss: 2.3056 - val_accuracy: 0.0625\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 2.3036 - accuracy: 0.1043 - val_loss: 2.3027 - val_accuracy: 0.1250\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 6s 936ms/step - loss: 2.2955 - accuracy: 0.1350 - val_loss: 2.2866 - val_accuracy: 0.1562\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 2.3210 - accuracy: 0.1288 - val_loss: 2.3057 - val_accuracy: 0.1250\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 6s 883ms/step - loss: 2.2865 - accuracy: 0.1288 - val_loss: 2.2674 - val_accuracy: 0.1562\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 8s 2s/step - loss: 2.2883 - accuracy: 0.1350 - val_loss: 2.2746 - val_accuracy: 0.1562\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 2.2878 - accuracy: 0.1288 - val_loss: 2.2440 - val_accuracy: 0.1250\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 6s 892ms/step - loss: 2.2590 - accuracy: 0.1595 - val_loss: 2.2319 - val_accuracy: 0.0938\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 2.2370 - accuracy: 0.1227 - val_loss: 2.2374 - val_accuracy: 0.1562\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 6s 903ms/step - loss: 2.2145 - accuracy: 0.1534 - val_loss: 2.2967 - val_accuracy: 0.0312\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 10s 2s/step - loss: 2.2051 - accuracy: 0.1719 - val_loss: 2.1963 - val_accuracy: 0.1250\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 2.1764 - accuracy: 0.1840 - val_loss: 2.2916 - val_accuracy: 0.2500\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 6s 1s/step - loss: 2.1854 - accuracy: 0.1927 - val_loss: 2.2999 - val_accuracy: 0.0938\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 2.1550 - accuracy: 0.1534 - val_loss: 2.3137 - val_accuracy: 0.1562\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 2.1480 - accuracy: 0.2025 - val_loss: 2.2310 - val_accuracy: 0.1250\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 6s 925ms/step - loss: 2.2084 - accuracy: 0.1718 - val_loss: 2.1034 - val_accuracy: 0.2812\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 2.1091 - accuracy: 0.2448 - val_loss: 2.1264 - val_accuracy: 0.1562\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 8s 2s/step - loss: 2.1162 - accuracy: 0.2331 - val_loss: 2.0936 - val_accuracy: 0.1562\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 6s 1s/step - loss: 2.0914 - accuracy: 0.2656 - val_loss: 2.0908 - val_accuracy: 0.2812\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.9989 - accuracy: 0.2577 - val_loss: 2.1468 - val_accuracy: 0.2812\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 2.0061 - accuracy: 0.2945 - val_loss: 2.0624 - val_accuracy: 0.1875\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 6s 924ms/step - loss: 2.0204 - accuracy: 0.2577 - val_loss: 2.1498 - val_accuracy: 0.1875\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 7s 942ms/step - loss: 2.0671 - accuracy: 0.2454 - val_loss: 2.1053 - val_accuracy: 0.1562\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 9s 2s/step - loss: 2.0462 - accuracy: 0.2577 - val_loss: 2.0414 - val_accuracy: 0.2500\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.9488 - accuracy: 0.3125 - val_loss: 2.0525 - val_accuracy: 0.2500\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.9209 - accuracy: 0.2883 - val_loss: 2.1685 - val_accuracy: 0.2812\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 6s 935ms/step - loss: 2.0340 - accuracy: 0.2393 - val_loss: 1.9755 - val_accuracy: 0.3125\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.8880 - accuracy: 0.2638 - val_loss: 2.0745 - val_accuracy: 0.1562\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 6s 885ms/step - loss: 1.9630 - accuracy: 0.2515 - val_loss: 2.1562 - val_accuracy: 0.1875\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 6s 879ms/step - loss: 1.8756 - accuracy: 0.3129 - val_loss: 2.1815 - val_accuracy: 0.3125\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.9414 - accuracy: 0.3190 - val_loss: 1.9232 - val_accuracy: 0.2812\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.8817 - accuracy: 0.2454 - val_loss: 1.7626 - val_accuracy: 0.3750\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 10s 2s/step - loss: 1.8153 - accuracy: 0.3129 - val_loss: 1.9381 - val_accuracy: 0.3750\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 6s 895ms/step - loss: 1.9036 - accuracy: 0.2822 - val_loss: 2.1942 - val_accuracy: 0.3438\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 6s 888ms/step - loss: 1.7875 - accuracy: 0.3374 - val_loss: 1.9928 - val_accuracy: 0.3438\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.8339 - accuracy: 0.3067 - val_loss: 2.0978 - val_accuracy: 0.2500\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 6s 889ms/step - loss: 1.8327 - accuracy: 0.2393 - val_loss: 1.9245 - val_accuracy: 0.2500\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 8s 2s/step - loss: 1.7460 - accuracy: 0.3742 - val_loss: 2.0877 - val_accuracy: 0.2812\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.8936 - accuracy: 0.2393 - val_loss: 2.0700 - val_accuracy: 0.1875\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.7186 - accuracy: 0.3558 - val_loss: 1.9597 - val_accuracy: 0.2500\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 6s 898ms/step - loss: 1.8018 - accuracy: 0.3006 - val_loss: 2.0138 - val_accuracy: 0.2188\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 8s 1s/step - loss: 1.7211 - accuracy: 0.3190 - val_loss: 1.9910 - val_accuracy: 0.2500\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 6s 927ms/step - loss: 1.7555 - accuracy: 0.3067 - val_loss: 1.9038 - val_accuracy: 0.2812\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.7417 - accuracy: 0.3558 - val_loss: 1.8366 - val_accuracy: 0.3438\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 7s 938ms/step - loss: 1.6223 - accuracy: 0.3926 - val_loss: 1.8938 - val_accuracy: 0.2500\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.7769 - accuracy: 0.3006 - val_loss: 1.9534 - val_accuracy: 0.2500\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.7489 - accuracy: 0.3190 - val_loss: 1.7609 - val_accuracy: 0.3438\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.7678 - accuracy: 0.3125 - val_loss: 1.8374 - val_accuracy: 0.2812\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.7144 - accuracy: 0.3497 - val_loss: 2.1837 - val_accuracy: 0.3438\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 8s 2s/step - loss: 1.7681 - accuracy: 0.3252 - val_loss: 2.0146 - val_accuracy: 0.1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.n//test_generator.batch_size)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmucBgi8DKFZ",
        "outputId": "4cc24117-99ba-4d33-9d63-b40b508df9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 446ms/step - loss: 1.5678 - accuracy: 0.4554\n",
            "Test accuracy: 0.4553571343421936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "validation_generator.reset()  # reset the generator to the beginning of the validation dataset\n",
        "\n",
        "predictions = model.predict(validation_generator, steps=validation_generator.n//validation_generator.batch_size+1)\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "true_classes = validation_generator.classes\n",
        "class_labels = list(validation_generator.class_indices.keys())\n",
        "\n",
        "print('Predictions:', predicted_classes)\n",
        "print('True classes:', true_classes)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_matrix = tf.math.confusion_matrix(labels=true_classes, predictions=predicted_classes)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxnj49qqGh8s",
        "outputId": "6bb968ed-9940-4b3b-d3d4-1f598aed74fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 111ms/step\n",
            "Predictions: [0 0 6 0 1 3 6 7 4 6 1 9 3 7 3 7 4 5 9 8 3 5 5 7 9 8 9 0 6 2 7 5 9 1 0 0 3\n",
            " 1 9 4 6 9 8 0 5]\n",
            "True classes: [0 0 0 0 1 1 1 1 1 1 2 2 2 3 3 3 3 4 4 4 4 4 5 5 5 5 6 6 6 6 6 7 7 7 7 8 8\n",
            " 8 8 8 9 9 9 9 9]\n",
            "Confusion matrix:\n",
            "tf.Tensor(\n",
            "[[3 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 1 1 0 2 1 0 0]\n",
            " [0 1 0 1 0 0 0 0 0 1]\n",
            " [0 0 0 1 1 0 0 2 0 0]\n",
            " [0 0 0 1 0 2 0 0 1 1]\n",
            " [0 0 0 0 0 1 0 1 1 1]\n",
            " [1 0 1 0 0 0 1 1 0 1]\n",
            " [1 1 0 0 0 1 0 0 0 1]\n",
            " [1 1 0 1 1 0 0 0 0 1]\n",
            " [1 0 0 0 0 1 1 0 1 1]], shape=(10, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycxxz5rzHGsI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}